{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emElxJbdWp-C"
   },
   "source": [
    "# PART1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf-7qVHoAvRa"
   },
   "source": [
    "# Read and Analyse Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JjpeR_PXGqe"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBbvkXKfXOX_",
    "outputId": "1e787479-aea5-435f-c09a-cb1b36935bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P8fK1olEaTlu"
   },
   "outputs": [],
   "source": [
    " project_path  = '/content/drive/MyDrive/AIML/projects/NLP/Project1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nC5j91lFaZce"
   },
   "outputs": [],
   "source": [
    "#load the full set of the data\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "blog_df = pd.read_csv(\"/content/drive/MyDrive/AIML/projects/NLP/Project1/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6T9n0k0earMm",
    "outputId": "127bd737-44a7-4219-95a2-67c1fd2e546c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data frame by using the shape attribute of the data frame\n",
    "blog_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cbAO2G-BcK7v",
    "outputId": "12e82f41-d61e-40ae-d4e0-beaffc995765"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ad21c61e-8f7d-4d54-b866-3d1490433d69\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132214</th>\n",
       "      <td>3665244</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>29,June,2004</td>\n",
       "      <td>I have completed my move.  To say I am sett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330319</th>\n",
       "      <td>3305513</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Man, what a heart breaking lost for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265538</th>\n",
       "      <td>3604179</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>I was too tired to write the softball u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482293</th>\n",
       "      <td>3402111</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>20,May,2004</td>\n",
       "      <td>&amp;nbsp; Oof... this is my last day of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620987</th>\n",
       "      <td>1381825</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>07,June,2004</td>\n",
       "      <td>urlLink Kit  posted the picture of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad21c61e-8f7d-4d54-b866-3d1490433d69')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ad21c61e-8f7d-4d54-b866-3d1490433d69 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ad21c61e-8f7d-4d54-b866-3d1490433d69');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             id  ...                                               text\n",
       "132214  3665244  ...     I have completed my move.  To say I am sett...\n",
       "330319  3305513  ...             Man, what a heart breaking lost for...\n",
       "265538  3604179  ...         I was too tired to write the softball u...\n",
       "482293  3402111  ...         &nbsp; Oof... this is my last day of su...\n",
       "620987  1381825  ...          urlLink Kit  posted the picture of the...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the data frame is properly loaded using the sample() method\n",
    "blog_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeZaZjMQdYb1",
    "outputId": "0daeecf4-61bd-4fce-9c78-ba3c1cc5d899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WkYXYUPtjHc4"
   },
   "outputs": [],
   "source": [
    "#Taking Sample of 5000 records to avoid session crash in google colab.\n",
    "# Google Colab is crashing so we have to reduce the size of data\n",
    "blog_df=blog_df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8Do6ikXj9Nn",
    "outputId": "6dab04bd-2154-4090-d71c-15e44aa7596b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5000 non-null   int64 \n",
      " 1   gender  5000 non-null   object\n",
      " 2   age     5000 non-null   int64 \n",
      " 3   topic   5000 non-null   object\n",
      " 4   sign    5000 non-null   object\n",
      " 5   date    5000 non-null   object\n",
      " 6   text    5000 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 273.6+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE699gQakFrZ",
    "outputId": "c99f55c9-5636-442c-ce5b-66eaa9ea97d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      3294\n",
       "female    1706\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "P8y50LvK5jpe",
    "outputId": "e968ba4c-cf23-48f2-93ef-158832faad8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a02c72210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='gender',data=blog_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWfmp46G52cX"
   },
   "source": [
    "**Male blogs are more than female blogs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztmhLkEB5o-z",
    "outputId": "1cd67fc0-ab47-4f59-d509-f568125e3d82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aries          2483\n",
       "Sagittarius     704\n",
       "Libra           414\n",
       "Scorpio         408\n",
       "Aquarius        329\n",
       "Leo             190\n",
       "Taurus          100\n",
       "Cancer           94\n",
       "Gemini           86\n",
       "Capricorn        84\n",
       "Pisces           67\n",
       "Virgo            41\n",
       "Name: sign, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df['sign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQTBTFie6DRw"
   },
   "source": [
    "**Aries Sign count is more in the sample data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dkhw4cRV5tgR",
    "outputId": "45e2054c-aa62-446d-96d9-f563d2327e03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Technology              2332\n",
       "indUnk                  1381\n",
       "Student                  569\n",
       "Engineering              119\n",
       "Education                118\n",
       "BusinessServices          87\n",
       "Sports-Recreation         75\n",
       "InvestmentBanking         70\n",
       "Communications-Media      61\n",
       "Non-Profit                47\n",
       "Science                   33\n",
       "Arts                      31\n",
       "Internet                  20\n",
       "Banking                   16\n",
       "Consulting                16\n",
       "Automotive                14\n",
       "Religion                   4\n",
       "Law                        3\n",
       "Accounting                 2\n",
       "Museums-Libraries          2\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY-k9zat6KZY"
   },
   "source": [
    "**Topic Technology count is more in sample data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG7IR89O47Uz"
   },
   "source": [
    "# Clean the Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK7Og_GjlVO4",
    "outputId": "808faa8f-701c-4035-afa1-3acb8d7a3346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for na values\n",
    "blog_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wplUaXBV5Ksq"
   },
   "outputs": [],
   "source": [
    "blog_df.drop(['id','date'],axis= 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85_t5tli5N-V",
    "outputId": "9d15b255-ef57-4f8f-b3fe-e27d32347206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   gender  5000 non-null   object\n",
      " 1   age     5000 non-null   int64 \n",
      " 2   topic   5000 non-null   object\n",
      " 3   sign    5000 non-null   object\n",
      " 4   text    5000 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlY013tgxOsQ"
   },
   "source": [
    "# Preprocess unstructured data to make it consumable for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS5O30bGxQfW"
   },
   "source": [
    "- Eliminate All special Characters and Numbers \n",
    "- Lowercase all textual data \n",
    "- Remove all Stopwords\n",
    "- Remove all extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "j8b66JXExdC9",
    "outputId": "9d8c68cb-7c10-4a9b-8da6-fd497798ca8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"             Over the last few weeks I've been to a couple of Western movies ( urlLink Troy  and  urlLink Spiderman 2 ) and a few Korean ones as well:  urlLink 여친소 (Yeochinso/Windstruck) ;  urlLink 올드보이 (Old Boy) ;  urlLink 공공의적 (Gong-gong-ui Jock/Public Enemy ;  urlLink 와일드카드 (Wild Card) ; and  urlLink 범죄의 재구성 (Beomjwi-ui Jaegooseong/The Big Swindle) . I really liked all of the Korean movies (actually the Western ones seemed pretty predictable compared to the Korean fare) but found it interesting that 4 of the 5 (all but Old Boy) were cop movies. (To be fair, in The Big Swindle it was more about the robbers than the cops--still, the theme was intact.) Maybe this is typical to movies in general (going in phases, all of the movies are from the last year) or maybe it's just how (again) in Korea things are very much fads; where once a theme gets started it's difficult to stop it.    urlLink     Public Enemy, WildCard, The Big Swindle and Old Boy    With that in mind, I think of my night out on Saturday. A group of friends and I had dinner and a movie in the 동대문 ( urlLink Dongdaemoon ) area then headed to 대학로 (pronounced Daehan-ro, but the Korean spelling is Dae-Hak-Ro: Daehak means university, ro is street, so (as you may have guessed) it is a street near universities--so, of course, there are tons of bars there). It was raining as a typhoon is in town (see the  urlLink typhoon tracker page  for updates of when one is on its way here) so there weren't many people out on the town. (I, however, didn't mind it as the rain here is pretty warm and I was in shorts a shirt and cut-away sneakers...really quite comfortable.) We went to about 5 places before finding one called 꾼 (Kkoon, an intersting name). The gal running the place said it was their first business day, but the place was empty. The music, however, was really good so I said, 'Service.', as in: what will you give us to come in? She offered plates of snacks and such...sold! The prices were lower than I'm used to, too...a good place.   So, how does this connect? The ambiance. The bar was like many other ones out there with tables, low lighting, club music, and a table or two that has a trough in the middle for ice and imported beer and coolers (we had 8 different kinds). I guess this is a safe business strategy as it may be fatal to go out on a limb with a new concept in this town unless it does very well, in which case you'll have lots of imitators.   I wonder what the next trend will be? Whatever it is, it'll catch on fast.  urlLink (JoongAng Ilbo article on this topic.)           \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check those symbols in the row which we saw earlier\n",
    "blog_df['text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPwcIoKmzKKe"
   },
   "source": [
    "### Eliminate All special Characters and Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "R4NsePzOynfq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "blog_df.text = blog_df.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "C4H3ZG7LyyQU",
    "outputId": "43db549d-9029-4a46-ba38-fc3dc377d90a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Over the last few weeks I ve been to a couple of Western movies urlLink Troy and urlLink Spiderman and a few Korean ones as well urlLink Yeochinso Windstruck urlLink Old Boy urlLink Gong gong ui Jock Public Enemy urlLink Wild Card and urlLink Beomjwi ui Jaegooseong The Big Swindle I really liked all of the Korean movies actually the Western ones seemed pretty predictable compared to the Korean fare but found it interesting that of the all but Old Boy were cop movies To be fair in The Big Swindle it was more about the robbers than the cops still the theme was intact Maybe this is typical to movies in general going in phases all of the movies are from the last year or maybe it s just how again in Korea things are very much fads where once a theme gets started it s difficult to stop it urlLink Public Enemy WildCard The Big Swindle and Old Boy With that in mind I think of my night out on Saturday A group of friends and I had dinner and a movie in the urlLink Dongdaemoon area then headed to pronounced Daehan ro but the Korean spelling is Dae Hak Ro Daehak means university ro is street so as you may have guessed it is a street near universities so of course there are tons of bars there It was raining as a typhoon is in town see the urlLink typhoon tracker page for updates of when one is on its way here so there weren t many people out on the town I however didn t mind it as the rain here is pretty warm and I was in shorts a shirt and cut away sneakers really quite comfortable We went to about places before finding one called Kkoon an intersting name The gal running the place said it was their first business day but the place was empty The music however was really good so I said Service as in what will you give us to come in She offered plates of snacks and such sold The prices were lower than I m used to too a good place So how does this connect The ambiance The bar was like many other ones out there with tables low lighting club music and a table or two that has a trough in the middle for ice and imported beer and coolers we had different kinds I guess this is a safe business strategy as it may be fatal to go out on a limb with a new concept in this town unless it does very well in which case you ll have lots of imitators I wonder what the next trend will be Whatever it is it ll catch on fast urlLink JoongAng Ilbo article on this topic '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check those symbols in the row which we saw earlier\n",
    "blog_df['text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsNR7StszTDg"
   },
   "source": [
    "### Lower Case all textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h22FTHD9zdWV"
   },
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "blog_df.text = blog_df.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "LhIqmECxziaT",
    "outputId": "31a19173-258a-41e4-9c66-0915aad17e81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' over the last few weeks i ve been to a couple of western movies urllink troy and urllink spiderman and a few korean ones as well urllink yeochinso windstruck urllink old boy urllink gong gong ui jock public enemy urllink wild card and urllink beomjwi ui jaegooseong the big swindle i really liked all of the korean movies actually the western ones seemed pretty predictable compared to the korean fare but found it interesting that of the all but old boy were cop movies to be fair in the big swindle it was more about the robbers than the cops still the theme was intact maybe this is typical to movies in general going in phases all of the movies are from the last year or maybe it s just how again in korea things are very much fads where once a theme gets started it s difficult to stop it urllink public enemy wildcard the big swindle and old boy with that in mind i think of my night out on saturday a group of friends and i had dinner and a movie in the urllink dongdaemoon area then headed to pronounced daehan ro but the korean spelling is dae hak ro daehak means university ro is street so as you may have guessed it is a street near universities so of course there are tons of bars there it was raining as a typhoon is in town see the urllink typhoon tracker page for updates of when one is on its way here so there weren t many people out on the town i however didn t mind it as the rain here is pretty warm and i was in shorts a shirt and cut away sneakers really quite comfortable we went to about places before finding one called kkoon an intersting name the gal running the place said it was their first business day but the place was empty the music however was really good so i said service as in what will you give us to come in she offered plates of snacks and such sold the prices were lower than i m used to too a good place so how does this connect the ambiance the bar was like many other ones out there with tables low lighting club music and a table or two that has a trough in the middle for ice and imported beer and coolers we had different kinds i guess this is a safe business strategy as it may be fatal to go out on a limb with a new concept in this town unless it does very well in which case you ll have lots of imitators i wonder what the next trend will be whatever it is it ll catch on fast urllink joongang ilbo article on this topic '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check those symbols in the row which we saw earlier\n",
    "blog_df['text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t602LZXrz5qE"
   },
   "source": [
    "### Remove all stopwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9DmTdYD0DEE",
    "outputId": "8231e0a1-8c27-49dd-8097-6f568d7f3295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "# importing stopwords list\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DMEwHZ10Ibw",
    "outputId": "b79e545c-9843-458c-bc31-74e6f6a5d717"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "       'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "       'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "       'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "       'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "       'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "       \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "       'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "       'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "       'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "       'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the stopwords from nltk library\n",
    "sw = stopwords.words('english')\n",
    "# displaying the stopwords\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kS05Q-7i0PsP"
   },
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "blog_df.text = blog_df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "9nIxlkSy0mbf",
    "outputId": "7445a2cf-cc23-46f4-a2aa-35669ac9d145"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'last weeks couple western movies urllink troy urllink spiderman korean ones well urllink yeochinso windstruck urllink old boy urllink gong gong ui jock public enemy urllink wild card urllink beomjwi ui jaegooseong big swindle really liked korean movies actually western ones seemed pretty predictable compared korean fare found interesting old boy cop movies fair big swindle robbers cops still theme intact maybe typical movies general going phases movies last year maybe korea things much fads theme gets started difficult stop urllink public enemy wildcard big swindle old boy mind think night saturday group friends dinner movie urllink dongdaemoon area headed pronounced daehan ro korean spelling dae hak ro daehak means university ro street may guessed street near universities course tons bars raining typhoon town see urllink typhoon tracker page updates one way many people town however mind rain pretty warm shorts shirt cut away sneakers really quite comfortable went places finding one called kkoon intersting name gal running place said first business day place empty music however really good said service give us come offered plates snacks sold prices lower used good place connect ambiance bar like many ones tables low lighting club music table two trough middle ice imported beer coolers different kinds guess safe business strategy may fatal go limb new concept town unless well case lots imitators wonder next trend whatever catch fast urllink joongang ilbo article topic'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check those symbols in the row which we saw earlier\n",
    "blog_df['text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCVlXvjt3-GR"
   },
   "source": [
    "### Remove All Extra white Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WD6OcuGR4CF8"
   },
   "outputs": [],
   "source": [
    "# Strip unwanted spaces\n",
    "blog_df.text = blog_df.text.apply(lambda x: x.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "yKBIhiEA4Gft",
    "outputId": "1fa51b19-e42b-4754-ebe8-36f7c02bd09a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'last weeks couple western movies urllink troy urllink spiderman korean ones well urllink yeochinso windstruck urllink old boy urllink gong gong ui jock public enemy urllink wild card urllink beomjwi ui jaegooseong big swindle really liked korean movies actually western ones seemed pretty predictable compared korean fare found interesting old boy cop movies fair big swindle robbers cops still theme intact maybe typical movies general going phases movies last year maybe korea things much fads theme gets started difficult stop urllink public enemy wildcard big swindle old boy mind think night saturday group friends dinner movie urllink dongdaemoon area headed pronounced daehan ro korean spelling dae hak ro daehak means university ro street may guessed street near universities course tons bars raining typhoon town see urllink typhoon tracker page updates one way many people town however mind rain pretty warm shorts shirt cut away sneakers really quite comfortable went places finding one called kkoon intersting name gal running place said first business day place empty music however really good said service give us come offered plates snacks sold prices lower used good place connect ambiance bar like many ones tables low lighting club music table two trough middle ice imported beer coolers different kinds guess safe business strategy may fatal go limb new concept town unless well case lots imitators wonder next trend whatever catch fast urllink joongang ilbo article topic'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df['text'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFf8koGfBxu8"
   },
   "source": [
    "# As we want to make this into a multi-label classification problem, you are required to merge all the label columns together, so that we have all the labels together for a particular sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "t0gV17E9CZs1"
   },
   "outputs": [],
   "source": [
    "#blog_df['labels'] = blog_df.apply(lambda col : [col['gender'],col['age'],col['topic'],col['sign']], axis=1)\n",
    "blog_df['labels'] = blog_df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EwGHZMsxCdWB",
    "outputId": "f8043587-0939-4b85-93ea-aa2140ecdb7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3ce165ee-7cf0-461e-964a-c5c02b37a891\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ce165ee-7cf0-461e-964a-c5c02b37a891')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3ce165ee-7cf0-461e-964a-c5c02b37a891 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3ce165ee-7cf0-461e-964a-c5c02b37a891');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  gender  ...                                   labels\n",
       "0   male  ...                 [male, 15, Student, Leo]\n",
       "1   male  ...                 [male, 15, Student, Leo]\n",
       "2   male  ...                 [male, 15, Student, Leo]\n",
       "3   male  ...                 [male, 15, Student, Leo]\n",
       "4   male  ...  [male, 33, InvestmentBanking, Aquarius]\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5_DVJYQzym6"
   },
   "source": [
    "# Select only required columns from your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fvBkEhqGClQZ"
   },
   "outputs": [],
   "source": [
    "blog_df = blog_df[['text','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "A0Nu1GApCpp1",
    "outputId": "eaf31e3a-f7f5-47d3-c0b5-ee2428230f34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-34c9f675-5c8d-4fee-a2b7-88577e9013d4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34c9f675-5c8d-4fee-a2b7-88577e9013d4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-34c9f675-5c8d-4fee-a2b7-88577e9013d4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-34c9f675-5c8d-4fee-a2b7-88577e9013d4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text                                   labels\n",
       "0  info found pages mb pdf files wait untill team...                 [male, 15, Student, Leo]\n",
       "1  team members drewes van der laag urllink mail ...                 [male, 15, Student, Leo]\n",
       "2  het kader van kernfusie op aarde maak je eigen...                 [male, 15, Student, Leo]\n",
       "3                                    testing testing                 [male, 15, Student, Leo]\n",
       "4  thanks yahoo toolbar capture urls popups means...  [male, 33, InvestmentBanking, Aquarius]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ssZyI5QxfBd"
   },
   "source": [
    "# Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Fv07cfbOxid1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(blog_df.text.values, blog_df.labels.values, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duFeK5I4xp32"
   },
   "source": [
    "# Vectorize the data\n",
    "In Machine Learning, vectorization is a step in feature extraction. The idea is to get some distinct features out of the text for the model to train on, by converting text to numerical vectors.\n",
    "\n",
    "- **BOW** - Bag of words is a Natural Language Processing technique of text modelling. In technical terms, we can say that it is a method of feature extraction with text data. This approach is a simple and flexible way of extracting features from documents.A bag of words is a representation of text that describes the occurrence of words within a document. We just keep track of word counts and disregard the grammatical details and the word order. It is called a “bag” of words because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.\n",
    "\n",
    "* **TF-IDF** --Term Frequency-Inverse Document Frequency. This is a metric that represents how ‘important’ a word is to a document in the document set. It has many uses, most importantly in automated text analysis, and is very useful for scoring words in machine learning algorithms for Natural Language Processing (NLP).This is a technique to quantify words in a set of documents. We generally compute a score for each word to signify its importance in the document and corpus. This method is a widely used technique in Information Retrieval and Text Mining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YulggRM-xtez"
   },
   "source": [
    "# Create Bag of Words\n",
    "Use CountVectorizer. Most simple of all the techniques.Thus we can manipulate the features any way we want. In fact, we can also combine unigrams, bigrams, trigrams, and more, to form feature space.\n",
    "\n",
    "Transform the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2DEtHoQbxy1R"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Considered unigrams and bigrams\n",
    "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99kqqDbcx3Cn"
   },
   "source": [
    "### Have a look at some feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDJTJ-mOx6yv",
    "outputId": "436f4516-f2c6-478c-b432-b60b14b0d390"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aa', 'aa amazing', 'aa compared', 'aa nice', 'aaa']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGubf1Slx_fb"
   },
   "source": [
    "# View term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiUxiy76yB9v",
    "outputId": "820b3803-64a6-4c11-94a9-bf0b1d66fc1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVM3t5P8yGcd"
   },
   "source": [
    "# Create a dictionary to get label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "JUvavsYqyJfg"
   },
   "outputs": [],
   "source": [
    "label_counts = dict()\n",
    "\n",
    "for labels in blog_df.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxhGd_ngyQYB"
   },
   "source": [
    "# Print the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBKZ-THdySne",
    "outputId": "bdfaadf0-6ed3-4e04-cd8e-ceaaf996cd00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'14': 170,\n",
       " '15': 339,\n",
       " '16': 67,\n",
       " '17': 331,\n",
       " '23': 137,\n",
       " '24': 353,\n",
       " '25': 268,\n",
       " '26': 96,\n",
       " '27': 86,\n",
       " '33': 101,\n",
       " '34': 540,\n",
       " '35': 2307,\n",
       " '36': 60,\n",
       " '37': 19,\n",
       " '39': 79,\n",
       " '41': 14,\n",
       " '42': 9,\n",
       " '44': 3,\n",
       " '45': 14,\n",
       " '46': 7,\n",
       " 'Accounting': 2,\n",
       " 'Aquarius': 329,\n",
       " 'Aries': 2483,\n",
       " 'Arts': 31,\n",
       " 'Automotive': 14,\n",
       " 'Banking': 16,\n",
       " 'BusinessServices': 87,\n",
       " 'Cancer': 94,\n",
       " 'Capricorn': 84,\n",
       " 'Communications-Media': 61,\n",
       " 'Consulting': 16,\n",
       " 'Education': 118,\n",
       " 'Engineering': 119,\n",
       " 'Gemini': 86,\n",
       " 'Internet': 20,\n",
       " 'InvestmentBanking': 70,\n",
       " 'Law': 3,\n",
       " 'Leo': 190,\n",
       " 'Libra': 414,\n",
       " 'Museums-Libraries': 2,\n",
       " 'Non-Profit': 47,\n",
       " 'Pisces': 67,\n",
       " 'Religion': 4,\n",
       " 'Sagittarius': 704,\n",
       " 'Science': 33,\n",
       " 'Scorpio': 408,\n",
       " 'Sports-Recreation': 75,\n",
       " 'Student': 569,\n",
       " 'Taurus': 100,\n",
       " 'Technology': 2332,\n",
       " 'Virgo': 41,\n",
       " 'female': 1706,\n",
       " 'indUnk': 1381,\n",
       " 'male': 3294}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g43DElbjyXrz"
   },
   "source": [
    "# Multi label binarizer\n",
    "Load a multilabel binarizer and fit it on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fEO40kkUzFdq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "dIdVZrfPya5P"
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(label_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdFOMINiG1te"
   },
   "source": [
    "# Build a base model for Supervised Learning - Classification\n",
    "\n",
    "Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "hAqprfk3G-qy"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf = OneVsRestClassifier(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LnkCORDHDt2"
   },
   "source": [
    "### Fit the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdZ4a6BJHIWk",
    "outputId": "d8f8b23d-7d50-4b62-d74b-eec33a2ef83b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wF0lpzxuHOGf"
   },
   "source": [
    "# Make predictions\n",
    "Get predicted labels and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "pE2bth7HHTeo"
   },
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_test_bow)\n",
    "predicted_scores = clf.decision_function(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0W2NbF8HWVE"
   },
   "source": [
    "# Get inverse transform for predicted labels and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "uOIiAnygHaJv"
   },
   "outputs": [],
   "source": [
    "pred_inversed = mlb.inverse_transform(predicted_labels)\n",
    "y_test_inversed = mlb.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgcKLFEBHemY"
   },
   "source": [
    "# Print some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvxmwHiPHjGW",
    "outputId": "bcca9ab0-0705-4fab-a97f-1152e7efdda1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\tbeautiful\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Title:\tgood idea johnathan quite tasty\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Title:\thouse right\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Title:\tsorry im person could wouldnt bad already went harry today went sledding quiet awhile ran tom scott went sledding got cold hungry decided head back goofed ate dinner realized needed along time ago way one stuck depressed time odd one whole vegetarian scheme normal like every ska bunctious kid maybe wouldnt problem thats problem im deep thought im going go listen early november think stuff nights long hope never come\n",
      "True labels:\t15,Libra,Student,female\n",
      "Predicted labels:\tfemale\n",
      "\n",
      "\n",
      "Title:\tbaby named bo jangles born parents told blind bo blind doctors foreign believed blind really light colored eyes growing tryed convince parents wasnt blind would never listen started pretend blind person believed kid named johnreed fathers highly involved mob organized crime john dad boss bo dad right hand man familys really good friends like family one day john making fun bo blindness throwing apple bo mob meeting bo blind caught john asked bo color hair bo like brown freak john realized cool bo became best friends kinda stupid yeah got like lost whole bunch one day bo jangles johnreed way gas station pick tacos desided take short cut throw corn field geuss got lost started going throw corn rows sudden spoted sign read dont mess crotch goblins john reed siad caitlin kyle girl school always talking things sudden c gob bounced bo jangles head hiss bo took c gob took head took bite taste like sorta weirdness dont think u ate stupid said johnrxxd dont care bo said sudden nosie coming corn rows u c gob caitlin hey caitlin said john hey john n one u ate c gob u realize last one left bo siad sorry didnt realize caitlin runs bo beats caitlin realizing didnt really matter ask midddle corn field john answers qwest tacos got really lost join think could help saids caitlin answer yes continue mission day turned night began get tierd could barely see anything walked rightt man man really tall bo took keyring flashlight tapped back man turned around bob janitor heck mr bob u corn field simple mr reed jeepers creepers inside bob u know using body really said bo since u found secert send u one person help u kids huddle togther think person want wait one person one friend meet girl playing line bingo ago told friends told would friend send u thanks siad sudden girl appears jeepers creepers flys away cant danielle says john aww one mintue bed next corn field explaining expalined danielle geuss stuck u guys saids danielle geuss bad continued got disscouraged begun believe lost ever walking corn field caitlin tripped bar typed object water spicket took drink went sleep next day woke figured wtare magical turned mult colored weird effect wasnt perment thanx goodness continued qwest found small shack could barely fit filled cotton candy little boy inside big bug eyes also lazyeyes one eye cotton unexpected geust boy said small voice forever main house life sudden doors windows dissappeared nothing look puzzlement going said bo know know eating great candy said danielle good idea sit eat candy boy explains got lost one day found house stuck last years wow amazing guess ever yeah least arnt alone yeah parents going freaked okay think love cotton candy saids danielle yeah said next years ate cotton candy played qwuestions end go insane become addiccted bark\n",
      "True labels:\t15,Libra,Science,male\n",
      "Predicted labels:\t15,Libra,female\n",
      "\n",
      "\n",
      "Title:\tpost properly later shld skool instead listnin music doin german coursework hoobastank cool example running away want give leave life collecting dust want feel sorry never gave us chance need side tell everything alright wanted tell truth know running away running away cause enough show willing give sacrifice one lifting thought life enough get close turn away nothing say need tell truth know running away running away nothing make change mind nothing waste time nothing make change mind running away running away got say running away make admit afraid running away hmm turn music go school disturbed angel beautifully decayed\n",
      "True labels:\t17,Gemini,Student,female\n",
      "Predicted labels:\tStudent,female\n",
      "\n",
      "\n",
      "Title:\tput anything new soory watching tv last week hit rock bottom fox showed ever enthralling wants princess sucked stupider watched well one good part modeling showed likes dislikes everyone dislikes like mean people ignorant people dishonesty one girl moth ball hyper dogs wanted jump screen give big smooch hand crown mean real laughed like minutes solid saw prince like glad win troll rather hop benjamin results giver resume would say special liaison judges think funny went vacay maybe highlights damn salazar\n",
      "True labels:\t24,Engineering,Libra,male\n",
      "Predicted labels:\t24,male\n",
      "\n",
      "\n",
      "Title:\tdoubt negative self image limited children due recess easily dismissed immaturity understand opening comment joke still unfortunate many think way\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Title:\tirony irony damn happy belated birthday chris stay dry everybody\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Title:\tstumbled website looking information amnesty international group declared july st murderess christa pike beyond doubt guilty crime wanted know crimes committed search google site among many others came difficult saying people life spared want know defending woman criminally insane say least vicious killer still believe killed imagine pain horror victim went nothing take away stain humanity\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\tAries,male\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_test[i],\n",
    "        ','.join(y_test_inversed[i]),\n",
    "        ','.join(pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Itw6U2rHoyg"
   },
   "source": [
    "# Calculate accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPvtwHgzCTaH"
   },
   "source": [
    "- **Accuracy** :  is the fraction of predictions our model got right.\n",
    "- **Precision**: Out of all the classes, precision is how much we predicted correctly.Precision should be as high as possible.\n",
    "- **Recall**: Out of all the positive classes, recall is how much we predicted correctly. It is also called sensitivity or true positive rate (TPR).Recall should be as high as possible.\n",
    "- **F-1 Score** - It is often convenient to combine precision and recall into a single metric called the F-1 score.The classifier will only get a high F-1 score if both recall and precision are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3RYO4WVEHw_D"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def print_evaluation_scores(y_val, predicted):\n",
    "    print('Accuracy score: ', accuracy_score(y_val, predicted))\n",
    "    print('F1 score: ', f1_score(y_val, predicted, average='micro'))\n",
    "    print('Average precision score: ', average_precision_score(y_val, predicted, average='micro'))\n",
    "    print('Average recall score: ', recall_score(y_val, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWmF6e9-H0Kx",
    "outputId": "a696e5d1-a0a6-4cc4-e5d5-9c20167a634c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "Accuracy score:  0.497\n",
      "F1 score:  0.7208410285551924\n",
      "Average precision score:  0.5565734251032868\n",
      "Average recall score:  0.63425\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-B8jf8eEHaZ"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "zhzz6ohPMt1v"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def build_model_train(X_train, y_train, X_valid=None, y_valid=None, C=1.0, model='lr'):\n",
    "    if model=='lr':\n",
    "        model = LogisticRegression(C=C, penalty='l1', dual=False, solver='liblinear')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    elif model=='svm':\n",
    "        model = LinearSVC(C=C, penalty='l1', dual=False, loss='squared_hinge')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    elif model=='nbayes':\n",
    "        model = MultinomialNB(alpha=1.0)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    elif model=='lda':\n",
    "        model = LinearDiscriminantAnalysis(solver='svd')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=2,\n",
    "                                             algorithm='auto')\n",
    "\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='adaboost':\n",
    "        model = AdaBoostClassifier()\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='rf':\n",
    "        model = RandomForestClassifier(n_estimators=2,\n",
    "        min_samples_split= 2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features= 'sqrt',\n",
    "        max_depth= 2,\n",
    "        criterion= 'gini',\n",
    "        bootstrap= False)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    elif model=='dt':\n",
    "        model = DecisionTreeClassifier(criterion=\"gini\", random_state=42,max_depth=3, min_samples_leaf=5)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dY1t-_mmMy56",
    "outputId": "b3766287-0ad6-4fd0-b22e-9dff06f35e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=LogisticRegression(penalty='l1',\n",
      "                                                 solver='liblinear'))\n",
      "\n",
      "Accuracy score:  0.501\n",
      "F1 score:  0.7448219845674834\n",
      "Average precision score:  0.5817361398156349\n",
      "Average recall score:  0.68775\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=LinearSVC(dual=False, penalty='l1'))\n",
      "\n",
      "Accuracy score:  0.476\n",
      "F1 score:  0.7399121054734319\n",
      "Average precision score:  0.5724503762810973\n",
      "Average recall score:  0.6945\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=MultinomialNB())\n",
      "\n",
      "Accuracy score:  0.139\n",
      "F1 score:  0.4978494623655914\n",
      "Average precision score:  0.35362416197843416\n",
      "Average recall score:  0.34725\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=False,\n",
      "                                                     max_depth=2,\n",
      "                                                     max_features='sqrt',\n",
      "                                                     n_estimators=2))\n",
      "\n",
      "Accuracy score:  0.001\n",
      "F1 score:  0.47034400948991695\n",
      "Average precision score:  0.2738760797969982\n",
      "Average recall score:  0.3965\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=KNeighborsClassifier(n_neighbors=2))\n",
      "\n",
      "Accuracy score:  0.099\n",
      "F1 score:  0.20382402079079265\n",
      "Average precision score:  0.11823347085369434\n",
      "Average recall score:  0.13725\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=AdaBoostClassifier())\n",
      "\n",
      "Accuracy score:  0.44\n",
      "F1 score:  0.7071571906354515\n",
      "Average precision score:  0.5276799173994138\n",
      "Average recall score:  0.66075\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=DecisionTreeClassifier(max_depth=3,\n",
      "                                                     min_samples_leaf=5,\n",
      "                                                     random_state=42))\n",
      "\n",
      "Accuracy score:  0.411\n",
      "F1 score:  0.6293318547269198\n",
      "Average precision score:  0.4328537763027495\n",
      "Average recall score:  0.5675\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "models = ['lr','svm','nbayes','rf','knn','adaboost','dt']\n",
    "\n",
    "for model in models:\n",
    "    model = build_model_train(X_train_bow, y_train,model=model)\n",
    "    model.fit(X_train_bow, y_train)\n",
    "    Ypred=model.predict(X_test_bow)\n",
    "    print(\"\\n\")\n",
    "    print(f\"**displaying  metrics for the mode {model}\\n\")\n",
    "    \n",
    "    print_evaluation_scores(y_test, Ypred)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFB5DwGlro4n"
   },
   "source": [
    "# Improve Performance of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Czo8szfGrvXj"
   },
   "source": [
    "### Experiment with other vectorisers\n",
    "\n",
    "**TF-IDF** --> TF-IDF or Term Frequency–Inverse Document Frequency, is a numerical statistic that’s intended to reflect how important a word is to a document. Although it’s another frequency-based method, it’s not as naive as Bag of Words.TF-IDF is a product of two values: Term Frequency (TF) and Inverse Document Frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "IbKfRK1Trzgm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#tf idf\n",
    "tf_idf = TfidfVectorizer()\n",
    "#applying tf idf to training data\n",
    "X_train_tf = tf_idf.fit_transform(X_train)\n",
    "#applying tf idf to training data\n",
    "X_train_tf = tf_idf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1poLAjS-8rDG",
    "outputId": "2a82567d-db7c-4508-b7e4-4aa6820aaf15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDgc7ITV9iel",
    "outputId": "4118d03e-5268-4248-fa47-0c959ca93c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.90800525 8.60115243 8.60115243 ... 8.60115243 8.60115243 8.60115243]\n"
     ]
    }
   ],
   "source": [
    "#Focus on TF IDF VALUES\n",
    "print(tf_idf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7M6FFoFvXCs",
    "outputId": "94008909-90ba-4fb1-fff8-cbc5494d0150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 4000, n_features: 28960\n"
     ]
    }
   ],
   "source": [
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "MO9LBDLLvf5o"
   },
   "outputs": [],
   "source": [
    "#transforming test data into tf-idf matrix\n",
    "X_test_tf = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN6gpdxvvsBZ",
    "outputId": "6a39c10d-cc3e-46d3-8e70-f9d1f102ed76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1000, n_features: 28960\n"
     ]
    }
   ],
   "source": [
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "JfVu-MvkEY2s"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def build_model_train_New(X_train, y_train, X_valid=None, y_valid=None, C=1.0, model='lr'):\n",
    "    if model=='lr':\n",
    "        model = LogisticRegression(C=C, penalty='l1', dual=False, solver='liblinear')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    elif model=='svm':\n",
    "        model = LinearSVC(C=C, penalty='l1', dual=False, loss='squared_hinge')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    \n",
    "    elif model=='nbayes':\n",
    "        model = MultinomialNB(alpha=1.0)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    elif model=='lda':\n",
    "        model = LinearDiscriminantAnalysis(solver='svd')\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='knn':\n",
    "        model = KNeighborsClassifier(n_neighbors=3,\n",
    "                                             algorithm='auto')\n",
    "\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='adaboost':\n",
    "        model = AdaBoostClassifier()\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='rf':\n",
    "        model = RandomForestClassifier(n_estimators=10,min_samples_split= 2,min_samples_leaf=1,max_features= 'sqrt',max_depth= 1,criterion= 'gini',bootstrap= False)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    elif model=='dt':\n",
    "        model = DecisionTreeClassifier(criterion=\"gini\", random_state=42,max_depth=3, min_samples_leaf=5)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RH-FYW0kv_N4",
    "outputId": "81c699b3-4689-497b-eac1-72b0ca2609c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=LogisticRegression(penalty='l1',\n",
      "                                                 solver='liblinear'))\n",
      "\n",
      "Accuracy score:  0.457\n",
      "F1 score:  0.6797873868697027\n",
      "Average precision score:  0.5028999211977936\n",
      "Average recall score:  0.5915\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=LinearSVC(dual=False, penalty='l1'))\n",
      "\n",
      "Accuracy score:  0.502\n",
      "F1 score:  0.7372395469165152\n",
      "Average precision score:  0.5765521821408841\n",
      "Average recall score:  0.659\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=MultinomialNB())\n",
      "\n",
      "Accuracy score:  0.156\n",
      "F1 score:  0.47747262609944363\n",
      "Average precision score:  0.3309371242662141\n",
      "Average recall score:  0.3325\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=False,\n",
      "                                                     max_depth=1,\n",
      "                                                     max_features='sqrt',\n",
      "                                                     n_estimators=10))\n",
      "\n",
      "Accuracy score:  0.0\n",
      "F1 score:  0.37409818757698393\n",
      "Average precision score:  0.22223930481283422\n",
      "Average recall score:  0.26575\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=KNeighborsClassifier(n_neighbors=3))\n",
      "\n",
      "Accuracy score:  0.087\n",
      "F1 score:  0.25088072471061906\n",
      "Average precision score:  0.11855494343127322\n",
      "Average recall score:  0.24925\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=AdaBoostClassifier())\n",
      "\n",
      "Accuracy score:  0.418\n",
      "F1 score:  0.7009095773140718\n",
      "Average precision score:  0.5192552103311597\n",
      "Average recall score:  0.655\n",
      "\n",
      "\n",
      "**displaying  metrics for the mode OneVsRestClassifier(estimator=DecisionTreeClassifier(max_depth=3,\n",
      "                                                     min_samples_leaf=5,\n",
      "                                                     random_state=42))\n",
      "\n",
      "Accuracy score:  0.404\n",
      "F1 score:  0.6280968858131488\n",
      "Average precision score:  0.4311533074935401\n",
      "Average recall score:  0.56725\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = ['lr','svm','nbayes','rf','knn','adaboost','dt']\n",
    "\n",
    "for model in models:\n",
    "    model = build_model_train_New(X_train_tf, y_train,model=model)\n",
    "    model.fit(X_train_tf, y_train)\n",
    "    Ypred1=model.predict(X_test_tf)\n",
    "    print(\"\\n\")\n",
    "    print(f\"**displaying  metrics for the mode {model}\\n\")\n",
    "    \n",
    "    print_evaluation_scores(y_test, Ypred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKthMwvsPkCT"
   },
   "source": [
    "# Share insights on relative performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxgH53mZPnid"
   },
   "source": [
    "### Which vectorizer performed better? Probable reason?.\n",
    "- Bag of Words just creates a set of vectors containing the count of word occurrences in the document (reviews), while the TF-IDF model contains information on the more important words and the less important ones as well.\n",
    "\n",
    "- Bag of Words vectors are easy to interpret. However, TF-IDF usually performs better in machine learning models.\n",
    "\n",
    "- The SVM with TF-IDF method generate the highest accuracy 50.2% compared to other methods, then LogisticRegression with Bag of words 50.1% and then last SVM with Bags of words 47% generate the highest accuracy.\n",
    "\n",
    "- Although Bag-of-Words is quite efficient and easy to implement, still there are some disadvantages to this technique which are given below:\n",
    "The model ignores the location information of the word. The location information is a piece of very important information in the text. For example  “today is off” and “Is today off”, have the exact same vector representation in the BoW model.\n",
    "Bag of word models doesn’t respect the semantics of the word. For example, words ‘soccer’ and ‘football’ are often used in the same context. However, the vectors corresponding to these words are quite different in the bag of words model. The problem becomes more serious while modeling sentences. Ex: “Buy used cars” and “Purchase old automobiles” are represented by totally different vectors in the Bag-of-words model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_zI5YQau8gl"
   },
   "source": [
    "### Which model outperformed? Probable reason?\n",
    "\n",
    "- The SVM with TF-IDF method generate the highest accuracy 50.2% as compared to other methods.\n",
    "- SVM is outperformed well on text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TcyFNzg1WzP"
   },
   "source": [
    "### Which parameter/hyperparameter significantly helped to improve performance?Probable reason?.\n",
    "\n",
    "- Below is a list of common hyperparameters that needs tuning for getting the best fit for our data. We'll try various hyperparameters settings to various splits of train/test data to find out best fit.\n",
    "\n",
    "- **C**- It represents regularization applied to the linear kernel function. The strength of normalization is inversely proportional to C which means that low C will result in high regularization and vice-versa. The default value of 1.0 is set.\n",
    "\n",
    "- **penalty**- It accepts one of the two string values. It applies a penalty to linear kernel function and prevents it from overfitting data.\n",
    "l1 Penalty\n",
    "l2 Penalty(default)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bymc2-wI-w9m"
   },
   "source": [
    "### According to you, which performance metric should be given most importance,why?.\n",
    "\n",
    "- According to me **Precision, Recall** should be given most importance as aims at they are measuring what proportion of actual positives was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGynSl5tA8EK"
   },
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-vWUcZAFKVI"
   },
   "source": [
    "# Basic Rule Based Chatbot using Chat and Reflections Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Xhdo0j9LFNX8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDwMdfU3FQ0z",
    "outputId": "2f5e84fd-44d4-4b39-a1c5-609bfebbb6a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 'you',\n",
       " 'i am': 'you are',\n",
       " 'i was': 'you were',\n",
       " \"i'd\": 'you would',\n",
       " \"i'll\": 'you will',\n",
       " \"i'm\": 'you are',\n",
       " \"i've\": 'you have',\n",
       " 'me': 'you',\n",
       " 'my': 'your',\n",
       " 'you': 'me',\n",
       " 'you are': 'I am',\n",
       " 'you were': 'I was',\n",
       " \"you'll\": 'I will',\n",
       " \"you've\": 'I have',\n",
       " 'your': 'my',\n",
       " 'yours': 'mine'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "xZvdclRAFYXu"
   },
   "outputs": [],
   "source": [
    "set_pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you doing today ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ], \n",
    "    [\n",
    "        r\"what is your name?\",\n",
    "        [\"You can call me a chatbot ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I am fine, thank you! How can i help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"I am fine, thank you\",\n",
    "        [\"great to hear that, how can i help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how can i help you? \",\n",
    "        [\"i am looking for online guides and courses to learn data science, can you suggest?\", \"i am looking for data science training platforms\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"That's great to hear\",\"How can i help you?:)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i am looking for online guides and courses to learn data science, can you suggest?\",\n",
    "        [\"Pluralsight is a great option to learn data science. You can check their website\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"thanks for the suggestion. do they have great authors and instructors?\",\n",
    "        [\"Yes, they have the world class best authors, that is their strength;)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) thank you so much, that was helpful\",\n",
    "        [\"I am happy to help\", \"No problem, you're welcome\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "    [\"Bye, take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3Lzz8TFFdpj",
    "outputId": "b64a43c5-3bab-431a-859a-06b163706f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am the chatbot you built\n"
     ]
    }
   ],
   "source": [
    "def chatbot():\n",
    "        print(\"Hello, I am the chatbot you built\") \n",
    "\n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QApV1l8JFmgW",
    "outputId": "44ce5c4b-f03c-46f2-9685-799d7d8cd128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.chat.util.Chat object at 0x7f09ff3c6850>\n"
     ]
    }
   ],
   "source": [
    "chat = Chat(set_pairs, reflections)\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvIgK66ZFsOl",
    "outputId": "cb685711-a34d-41ca-c897-8a55a3c6efd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Hello\n",
      "Hello\n",
      ">what is your name?\n",
      "You can call me a chatbot ?\n",
      ">How are you?\n",
      "I am fine, thank you! How can i help you?\n",
      ">i am looking for online guides and courses to learn data science, can you suggest?\n",
      "Pluralsight is a great option to learn data science. You can check their website\n",
      ">quit\n",
      "It was nice talking to you. See you soon :)\n",
      "Hello, I am the chatbot you built\n"
     ]
    }
   ],
   "source": [
    "chat.converse()\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRF8rbO9Go2i"
   },
   "source": [
    "# Customer Support Chatbot using Neural Networks and NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Dqb1ZfbGr90",
    "outputId": "b01b0f21-8ece-4b61-ad4f-c7cb73491d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "import numpy\n",
    "#import tflearn\n",
    "import tensorflow\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEGaNE2DGwKc"
   },
   "source": [
    "# Loading given json data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "_vB108GAG1E-"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/AIML/projects/NLP/Project1/GL Bot.json') as file:\n",
    "  data=json.load(file)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mayMvNBSHHaz",
    "outputId": "152056b1-7bbb-4bb7-9f46-ca4c903ac693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}]}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1a9s6M6HMz8",
    "outputId": "f2bdfb10-8e3f-49bb-e308-8e236b3f423e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}]\n"
     ]
    }
   ],
   "source": [
    "print (data['intents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXmx2U4OHSUm",
    "outputId": "220e8bd9-df75-4e40-fbd5-77409e39a239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro\n"
     ]
    }
   ],
   "source": [
    "print(data['intents'][0]['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SG6EvhufHWew",
    "outputId": "6dbd2f8f-05b3-473e-a613-fc0d35b6c7a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro\n",
      "['Hello! how can i help you ?']\n",
      "Exit\n",
      "['I hope I was able to assist you, Good Bye']\n",
      "Olympus\n",
      "['Link: Olympus wiki']\n",
      "SL\n",
      "['Link: Machine Learning wiki ']\n",
      "NN\n",
      "['Link: Neural Nets wiki']\n",
      "Bot\n",
      "['I am your virtual learning assistant']\n",
      "Profane\n",
      "['Please use respectful words']\n",
      "Ticket\n",
      "['Tarnsferring the request to your PM']\n"
     ]
    }
   ],
   "source": [
    "for each in data['intents']:\n",
    "  print(each['tag'])\n",
    "  print(each['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Bhi800cnwcK",
    "outputId": "be3c5574-4618-420b-c6d1-5665a3260533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro\n",
      "Exit\n",
      "Olympus\n",
      "SL\n",
      "NN\n",
      "Bot\n",
      "Profane\n",
      "Ticket\n"
     ]
    }
   ],
   "source": [
    "for each in data['intents']:\n",
    "  print(each['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxFdgOt-d6EU"
   },
   "source": [
    "# Adding more data to given json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "tNP2nCaId9Kb"
   },
   "outputs": [],
   "source": [
    "#Added new patterns data in Exit tag\n",
    "myThings = data['intents'][1]\n",
    "\n",
    "myThingsnew = data['intents'][1]['patterns'].append('great support')\n",
    "myThingsnew = data['intents'][1]['patterns'].append('great assistance')\n",
    "myThingsnew = data['intents'][1]['patterns'].append('bye')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsxXCd0j0mwp",
    "outputId": "66fc8b24-8fcc-46ab-dfd0-dea4a1515aca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_set': '',\n",
       " 'patterns': ['thank you',\n",
       "  'thanks',\n",
       "  'cya',\n",
       "  'see you',\n",
       "  'later',\n",
       "  'see you later',\n",
       "  'goodbye',\n",
       "  'i am leaving',\n",
       "  'have a Good day',\n",
       "  'you helped me',\n",
       "  'thanks a lot',\n",
       "  'thanks a ton',\n",
       "  'you are the best',\n",
       "  'great help',\n",
       "  'too good',\n",
       "  'you are a good learning buddy',\n",
       "  'great support',\n",
       "  'great assistance',\n",
       "  'bye'],\n",
       " 'responses': ['I hope I was able to assist you, Good Bye'],\n",
       " 'tag': 'Exit'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myThings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Q11ILf8_eJYO"
   },
   "outputs": [],
   "source": [
    "#Added new data(patterns) in Olympus tag\n",
    "\n",
    "myThings1 =data['intents'][2]\n",
    "\n",
    "myThingsnew = data['intents'][2]['patterns'].append('Is there any user guide for olympus?')\n",
    "myThingsnew = data['intents'][2]['patterns'].append('Where is the career opportunities page?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97X17jeX8Z35",
    "outputId": "69ca3c64-59e9-497d-f420-a9c0177546c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_set': '',\n",
       " 'patterns': ['olympus',\n",
       "  'explain me how olympus works',\n",
       "  'I am not able to understand olympus',\n",
       "  'olympus window not working',\n",
       "  'no access to olympus',\n",
       "  'unable to see link in olympus',\n",
       "  'no link visible on olympus',\n",
       "  'whom to contact for olympus',\n",
       "  'lot of problem with olympus',\n",
       "  'olypus is not a good tool',\n",
       "  'lot of problems with olympus',\n",
       "  'how to use olympus',\n",
       "  'teach me olympus',\n",
       "  'Is there any user guide for olympus?',\n",
       "  'Where is the career opportunities page?'],\n",
       " 'responses': ['Link: Olympus wiki'],\n",
       " 'tag': 'Olympus'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myThings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "v__2Kt36eKLa"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Added new data(patterns) in Ticket tag   \n",
    "myThings2 =data['intents'][7]\n",
    "\n",
    "myThingsnew1 = data['intents'][7]['patterns'].append('not satisfied')\n",
    "myThingsnew1 = data['intents'][7]['patterns'].append('ticket status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygEylffx9JrM",
    "outputId": "568b1433-4ee9-4c84-c567-6ff834a78cc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_set': '',\n",
       " 'patterns': ['my problem is not solved',\n",
       "  'you did not help me',\n",
       "  'not a good solution',\n",
       "  'bad solution',\n",
       "  'not good solution',\n",
       "  'no help',\n",
       "  'wasted my time',\n",
       "  'useless bot',\n",
       "  'create a ticket',\n",
       "  'not satisfied',\n",
       "  'ticket status'],\n",
       " 'responses': ['Tarnsferring the request to your PM'],\n",
       " 'tag': 'Ticket'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myThings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oHUGLsK9bz7",
    "outputId": "f9b45a11-2f0e-4303-8f93-b2adc77207cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'context_set': '',\n",
       "  'patterns': ['hi',\n",
       "   'how are you',\n",
       "   'is anyone there',\n",
       "   'hello',\n",
       "   'whats up',\n",
       "   'hey',\n",
       "   'yo',\n",
       "   'listen',\n",
       "   'please help me',\n",
       "   'i am learner from',\n",
       "   'i belong to',\n",
       "   'aiml batch',\n",
       "   'aifl batch',\n",
       "   'i am from',\n",
       "   'my pm is',\n",
       "   'blended',\n",
       "   'online',\n",
       "   'i am from',\n",
       "   'hey ya',\n",
       "   'talking to you for first time'],\n",
       "  'responses': ['Hello! how can i help you ?'],\n",
       "  'tag': 'Intro'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['thank you',\n",
       "   'thanks',\n",
       "   'cya',\n",
       "   'see you',\n",
       "   'later',\n",
       "   'see you later',\n",
       "   'goodbye',\n",
       "   'i am leaving',\n",
       "   'have a Good day',\n",
       "   'you helped me',\n",
       "   'thanks a lot',\n",
       "   'thanks a ton',\n",
       "   'you are the best',\n",
       "   'great help',\n",
       "   'too good',\n",
       "   'you are a good learning buddy',\n",
       "   'great support',\n",
       "   'great assistance',\n",
       "   'bye'],\n",
       "  'responses': ['I hope I was able to assist you, Good Bye'],\n",
       "  'tag': 'Exit'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['olympus',\n",
       "   'explain me how olympus works',\n",
       "   'I am not able to understand olympus',\n",
       "   'olympus window not working',\n",
       "   'no access to olympus',\n",
       "   'unable to see link in olympus',\n",
       "   'no link visible on olympus',\n",
       "   'whom to contact for olympus',\n",
       "   'lot of problem with olympus',\n",
       "   'olypus is not a good tool',\n",
       "   'lot of problems with olympus',\n",
       "   'how to use olympus',\n",
       "   'teach me olympus',\n",
       "   'Is there any user guide for olympus?',\n",
       "   'Where is the career opportunities page?'],\n",
       "  'responses': ['Link: Olympus wiki'],\n",
       "  'tag': 'Olympus'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['i am not able to understand svm',\n",
       "   'explain me how machine learning works',\n",
       "   'i am not able to understand naive bayes',\n",
       "   'i am not able to understand logistic regression',\n",
       "   'i am not able to understand ensemble techb=niques',\n",
       "   'i am not able to understand knn',\n",
       "   'i am not able to understand knn imputer',\n",
       "   'i am not able to understand cross validation',\n",
       "   'i am not able to understand boosting',\n",
       "   'i am not able to understand random forest',\n",
       "   'i am not able to understand ada boosting',\n",
       "   'i am not able to understand gradient boosting',\n",
       "   'machine learning',\n",
       "   'ML',\n",
       "   'SL',\n",
       "   'supervised learning',\n",
       "   'knn',\n",
       "   'logistic regression',\n",
       "   'regression',\n",
       "   'classification',\n",
       "   'naive bayes',\n",
       "   'nb',\n",
       "   'ensemble techniques',\n",
       "   'bagging',\n",
       "   'boosting',\n",
       "   'ada boosting',\n",
       "   'ada',\n",
       "   'gradient boosting',\n",
       "   'hyper parameters'],\n",
       "  'responses': ['Link: Machine Learning wiki '],\n",
       "  'tag': 'SL'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['what is deep learning',\n",
       "   'unable to understand deep learning',\n",
       "   'explain me how deep learning works',\n",
       "   'i am not able to understand deep learning',\n",
       "   'not able to understand neural nets',\n",
       "   'very diffult to understand neural nets',\n",
       "   'unable to understand neural nets',\n",
       "   'ann',\n",
       "   'artificial intelligence',\n",
       "   'artificial neural networks',\n",
       "   'weights',\n",
       "   'activation function',\n",
       "   'hidden layers',\n",
       "   'softmax',\n",
       "   'sigmoid',\n",
       "   'relu',\n",
       "   'otimizer',\n",
       "   'forward propagation',\n",
       "   'backward propagation',\n",
       "   'epochs',\n",
       "   'epoch',\n",
       "   'what is an epoch',\n",
       "   'adam',\n",
       "   'sgd'],\n",
       "  'responses': ['Link: Neural Nets wiki'],\n",
       "  'tag': 'NN'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['what is your name',\n",
       "   'who are you',\n",
       "   'name please',\n",
       "   'when are your hours of opertions',\n",
       "   'what are your working hours',\n",
       "   'hours of operation',\n",
       "   'working hours',\n",
       "   'hours'],\n",
       "  'responses': ['I am your virtual learning assistant'],\n",
       "  'tag': 'Bot'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['what the hell',\n",
       "   'bloody stupid bot',\n",
       "   'do you think you are very smart',\n",
       "   'screw you',\n",
       "   'i hate you',\n",
       "   'you are stupid',\n",
       "   'jerk',\n",
       "   'you are a joke',\n",
       "   'useless piece of shit'],\n",
       "  'responses': ['Please use respectful words'],\n",
       "  'tag': 'Profane'},\n",
       " {'context_set': '',\n",
       "  'patterns': ['my problem is not solved',\n",
       "   'you did not help me',\n",
       "   'not a good solution',\n",
       "   'bad solution',\n",
       "   'not good solution',\n",
       "   'no help',\n",
       "   'wasted my time',\n",
       "   'useless bot',\n",
       "   'create a ticket',\n",
       "   'not satisfied',\n",
       "   'ticket status'],\n",
       "  'responses': ['Tarnsferring the request to your PM'],\n",
       "  'tag': 'Ticket'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After adding new patterns intents look like below\n",
    "data['intents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHMSayP3mdwN",
    "outputId": "a2e4fff1-75ef-495a-983b-07ba21067883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro\n",
      "Exit\n",
      "Olympus\n",
      "SL\n",
      "NN\n",
      "Bot\n",
      "Profane\n",
      "Ticket\n"
     ]
    }
   ],
   "source": [
    "for each in data['intents']:\n",
    "  print(each['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfS7guoDISJ_"
   },
   "source": [
    "### Extracting data from json data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "5Lbz9VbiIWZx"
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "iQhXKxDlIZtB"
   },
   "outputs": [],
   "source": [
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        words.extend(wrds)\n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(intent[\"tag\"])\n",
    "        \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F61o6YHNIc6X"
   },
   "source": [
    "### Performing Stemming on the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ndLuW0SjIfqj"
   },
   "outputs": [],
   "source": [
    "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBHB6SwTIiKn"
   },
   "source": [
    "### Creating Bag of words for vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Dwt8uqHgInvu"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "    bag = []\n",
    "\n",
    "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "    for w in words:\n",
    "        if w in wrds:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "\n",
    "    output_row = out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "eUtkbvsOIq0H"
   },
   "outputs": [],
   "source": [
    "training = numpy.array(training)\n",
    "output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "LCXoc8RbItsN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense,Input,BatchNormalization,Activation,Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers,regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIQLOlXjIw5d",
    "outputId": "19c8dae0-6ca9-4eac-96d5-6fb83cc73a58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6crLYouIzv0",
    "outputId": "ee41a033-b75b-4898-c4b2-5b32d8f1e4f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 161)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bwumw1rYI5C_",
    "outputId": "2c8596d6-3108-465e-9b2c-e75e01649fa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_0ZdbO1I7xx",
    "outputId": "955defbe-492b-402b-ed34-5c7536ca579c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ettwPyeJJeh"
   },
   "source": [
    "# Creating a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "yWO60JzyJOgd"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(100,input_dim=len(training[0]),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvwbuvtbJceY",
    "outputId": "e6a744ef-c99c-4813-daf3-c7cf3247d190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               16200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,184\n",
      "Trainable params: 23,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QzRM7yiJjSu"
   },
   "source": [
    "### Compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "dnRbIZkCJnlq"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9,nesterov=True)\n",
    "adam = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-_SMOOHKXII",
    "outputId": "3d039e23-805f-426d-9733-d4155ed0d1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1166 - accuracy: 0.1481\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0691 - accuracy: 0.1778\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0417 - accuracy: 0.2074\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0483 - accuracy: 0.1926\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9955 - accuracy: 0.2593\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9959 - accuracy: 0.2222\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9722 - accuracy: 0.2667\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9537 - accuracy: 0.2444\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9418 - accuracy: 0.2593\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8932 - accuracy: 0.3704\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8960 - accuracy: 0.3037\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8869 - accuracy: 0.3556\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8477 - accuracy: 0.3481\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8079 - accuracy: 0.3852\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8041 - accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.7899 - accuracy: 0.3926\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7340 - accuracy: 0.4222\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.7389 - accuracy: 0.3852\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6789 - accuracy: 0.4370\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.6928 - accuracy: 0.4444\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5931 - accuracy: 0.5111\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5778 - accuracy: 0.5185\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5509 - accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5604 - accuracy: 0.5185\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.5101 - accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4721 - accuracy: 0.5111\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4041 - accuracy: 0.5926\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3747 - accuracy: 0.6074\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3961 - accuracy: 0.5778\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.5778\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3171 - accuracy: 0.5926\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2549 - accuracy: 0.6593\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2219 - accuracy: 0.6815\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2406 - accuracy: 0.6593\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1805 - accuracy: 0.6741\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1398 - accuracy: 0.7185\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1354 - accuracy: 0.7037\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.7630\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9742 - accuracy: 0.7852\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.7704\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9415 - accuracy: 0.8222\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9772 - accuracy: 0.7333\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9191 - accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8532 - accuracy: 0.7630\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7856 - accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8396 - accuracy: 0.8296\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7768 - accuracy: 0.8148\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.8444\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7410 - accuracy: 0.8741\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.8963\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.8222\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.8741\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.8815\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.8519\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8815\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9185\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8963\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.9037\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.9259\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.9037\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.9037\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.9037\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.9407\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.9407\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8963\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.9111\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.9333\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.9037\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.9556\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.9037\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.9556\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.9333\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9778\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9407\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.9333\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9407\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9481\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9926\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9852\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9704\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2001 - accuracy: 0.9556\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9704\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9778\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9778\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9704\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9852\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9778\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9704\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9481\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9704\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9926\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9704\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f09931685d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training, output, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgcdvN_-ZxM1"
   },
   "source": [
    "# Predicting from given model by first converting it into bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "5P6e8CnzZ1tU"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    #bag=[]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "      \n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99nyhyhAZ4t7"
   },
   "source": [
    "# Model predicting on the user input given and finding the most probable class. Finally, we randomly pick a response from that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "V7EUqGr5Z9cr"
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Hi!! I am GL-Bot. How can I help you today? (type quit to stop)!\")\n",
    "    while True:\n",
    "        inp = input(\"You: \")\n",
    "        if inp.lower() == \"quit\":\n",
    "          break\n",
    "        pp =bag_of_words(inp,words)\n",
    "        train=pp.reshape(161 ,1)\n",
    "        train=tensorflow.expand_dims(pp,axis=0)\n",
    "        #print(train.shape)\n",
    "        results = model.predict(train) \n",
    "         \n",
    "        #results = model.predict([bag_of_words(inp, words)])\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "\n",
    "        print(random.choice(responses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCBF14_zaADE",
    "outputId": "7540385b-b168-4c15-e812-d739b8043370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!! I am GL-Bot. How can I help you today? (type quit to stop)!\n",
      "You: Hello\n",
      "Hello! how can i help you ?\n",
      "You: need help with olympus\n",
      "Link: Olympus wiki\n",
      "You: cant understand regression\n",
      "Link: Machine Learning wiki \n",
      "You: why use weights in neural network?\n",
      "Link: Neural Nets wiki\n",
      "You: not a good solution\n",
      "Tarnsferring the request to your PM\n",
      "You: you are a stupid bot\n",
      "Please use respectful words\n",
      "You: ok goodbye\n",
      "I hope I was able to assist you, Good Bye\n",
      "You: Hello\n",
      "Hello! how can i help you ?\n",
      "You: Is there any user guide for olympus?\n",
      "Link: Olympus wiki\n",
      "You: great support\n",
      "I hope I was able to assist you, Good Bye\n",
      "You: bye\n",
      "I hope I was able to assist you, Good Bye\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIGrSL2foy6w"
   },
   "source": [
    "**Accuracy of model is 98%**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gauri_Desai_NLP_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
